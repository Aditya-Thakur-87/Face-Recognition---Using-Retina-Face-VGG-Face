"""
face_aligner_vgg.py
---------------------------------------------
Runtime face alignment module for VGGFace2 / InceptionResnetV1 pipeline.

Features:
 - Aligns faces using 5 facial landmarks (VGG-Face geometry)
 - Normalizes aligned face to [0,1] RGB (ready for embedding model)
 - Supports both single-face and multi-face alignment
 - Optionally saves aligned crops (denormalized BGR) for inspection
"""

import cv2
import numpy as np
import torch
import os


class FaceAlignerVGG:
    def __init__(self, output_size=(224, 224), device="cuda"):
        """
        Args:
            output_size: Target aligned face size (default 224√ó224)
            device: torch device ('cuda' or 'cpu')
        """
        self.output_size = output_size
        self.device = device

        # Reference 5-point geometry (VGG-Face standard)
        self.ref_pts = np.float32([
            [96.0, 112.0],   # left eye
            [160.0, 112.0],  # right eye
            [128.0, 160.0],  # nose
            [104.0, 200.0],  # left mouth
            [152.0, 200.0]   # right mouth
        ])

    # ------------------------------------------------------------
    def align_and_normalize(self, img, landmarks, save_dir=None, face_id=None):
        """
        Align and normalize a single face.

        Args:
            img: Original BGR image (numpy array)
            landmarks: np.ndarray of shape (5, 2)
            save_dir: Optional directory to save aligned image
            face_id: Optional name/ID for saving
        Returns:
            torch.Tensor (1, 3, 160, 160) normalized RGB in [0,1]
        """
        src_pts = landmarks.reshape((5, 2)).astype(np.float32)
        M = cv2.estimateAffinePartial2D(src_pts, self.ref_pts, method=cv2.LMEDS)[0]
        aligned = cv2.warpAffine(img, M, self.output_size, borderValue=0.0)

        # Convert to RGB and normalize to [0,1]
        aligned_rgb = cv2.cvtColor(aligned, cv2.COLOR_BGR2RGB)
        aligned_rgb = cv2.resize(aligned_rgb, (160, 160))
        aligned_rgb = aligned_rgb.astype(np.float32) / 255.0

        # Convert to (1, 3, H, W) tensor
        aligned_tensor = np.transpose(aligned_rgb, (2, 0, 1))
        aligned_tensor = torch.tensor(aligned_tensor, dtype=torch.float32).unsqueeze(0).to(self.device)

        # Optional save
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
            save_path = os.path.join(save_dir, f"{face_id or 'aligned_face'}.jpg")
            save_face = np.clip(aligned, 0, 255).astype(np.uint8)
            cv2.imwrite(save_path, save_face)
            print(f"üíæ Saved aligned face to: {save_path}")

        return aligned_tensor

    # ------------------------------------------------------------
    def align_multiple_faces(self, img, detected_faces, save_dir=None):
        """
        Align and normalize multiple faces from the same image.

        Args:
            img: Original BGR image
            detected_faces: list of dicts with key "landmarks"
            save_dir: Optional folder to save aligned images
        Returns:
            torch.Tensor (N, 3, 160, 160) batch tensor
        """
        tensors = []
        for i, face in enumerate(detected_faces):
            # ‚úÖ Use the face_id generated by detector, or fallback to face_{i+1}
            face_id = str(face.get("face_id", i + 1))

            landmarks = face["landmarks"]

            tensor = self.align_and_normalize(
                img,
                landmarks,
                save_dir=save_dir,
                face_id=face_id  # ‚úÖ keeps consistent naming
            )
            tensors.append(tensor)

        # ‚úÖ Handle case when no faces were detected
        if not tensors:
            print("‚ö†Ô∏è No valid faces found for alignment.")
            return None

        # ‚úÖ Stack into a batch tensor
        batch_tensor = torch.cat(tensors, dim=0)
        print(f"‚úÖ Aligned {len(tensors)} faces, batch shape: {batch_tensor.shape}")
        return batch_tensor

